{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy, pandas, matplotlib, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#PyTorch and its sub modules\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n",
    "from jpeg_to_num import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/keladaoba/Desktop/-Math_108C-Final-Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/keladaoba/Desktop/-Math_108C-Final-Project/data/data'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Current_Directory=os.getcwd()\n",
    "Image_Directory=os.path.join(Current_Directory, \"data/\", \"data\")\n",
    "Image_Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()])\n",
    "dataloader=DataLoader(dataset=torchvision.datasets.ImageFolder(os.path.join(Current_Directory, \"data/\"), transform=train_transform), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 218, 178])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1, 218, 178])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features=[]\n",
    "flag=1\n",
    "for train_features, train_labels in dataloader:\n",
    "    all_features.append(train_features)\n",
    "    \n",
    "    if flag==1:\n",
    "        print(f\"Feature batch shape: {train_features.shape}\")\n",
    "        flag=0\n",
    "\n",
    "all_features=torch.cat(all_features, dim=0)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn tensor into matrix\n",
    "mymat = np.asarray(all_features[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cov matrix\n",
    "def covariance(i):\n",
    "    X = mymat[i]\n",
    "    return (1/((X.shape[0]*X.shape[1])-1)) * np.transpose(X) @ X\n",
    "\n",
    "Cov = covariance(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquire all eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(Cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04598402,  0.0403565 , -0.11622447, ..., -0.02076791,\n",
       "         0.04141479,  0.08969976],\n",
       "       [ 0.05382681, -0.0230995 ,  0.09688287, ..., -0.02429436,\n",
       "         0.04370163,  0.08895408],\n",
       "       [-0.02472555,  0.0548454 ,  0.00493543, ..., -0.02649797,\n",
       "         0.04345314,  0.08911831],\n",
       "       ...,\n",
       "       [-0.07990737,  0.03156812, -0.01776984, ..., -0.03539729,\n",
       "         0.03151438,  0.08723041],\n",
       "       [ 0.0224223 ,  0.01374722, -0.02780964, ..., -0.0426641 ,\n",
       "         0.0349314 ,  0.08777967],\n",
       "       [-0.08706868, -0.0285493 ,  0.05495342, ..., -0.04819672,\n",
       "         0.03820106,  0.08810271]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort eigenvalues in descending order\n",
    "index = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "# sort eigenvalues\n",
    "sorted_eigenvalues = eigenvalues[index]\n",
    "\n",
    "# sort eigenvectors\n",
    "sorted_eigenvectors = eigenvectors[:,index]\n",
    "\n",
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select eigenvecgtors corresponding to the top 10 eigenvalues\n",
    "top_eigenvectors = sorted_eigenvectors[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biuld the projection matrix\n",
    "projection_matrix = top_eigenvectors @ np.transpose(top_eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.89484483, 0.89138097, 0.89597744, ..., 0.8216993 ,\n",
       "         0.83950365, 0.84738046],\n",
       "        [0.90190756, 0.89904016, 0.9040832 , ..., 0.8341555 ,\n",
       "         0.8513838 , 0.8571222 ],\n",
       "        [0.9052334 , 0.9026081 , 0.908222  , ..., 0.8434417 ,\n",
       "         0.8608325 , 0.86573356],\n",
       "        ...,\n",
       "        [0.361319  , 0.3529841 , 0.35681936, ..., 0.3613351 ,\n",
       "         0.3792637 , 0.37337857],\n",
       "        [0.401006  , 0.3954077 , 0.3999024 , ..., 0.37901217,\n",
       "         0.40160155, 0.3959066 ],\n",
       "        [0.428266  , 0.4235391 , 0.4275074 , ..., 0.38954443,\n",
       "         0.41488767, 0.40886062]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymat\n",
    "projected = mymat.dot(projection_matrix)\n",
    "projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 218, 178)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected.shape\n",
    "# this indicates that data needs to be reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected = projected.reshape(-1, 178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.894845</td>\n",
       "      <td>0.891381</td>\n",
       "      <td>0.895977</td>\n",
       "      <td>0.921408</td>\n",
       "      <td>0.939303</td>\n",
       "      <td>0.939943</td>\n",
       "      <td>0.941081</td>\n",
       "      <td>0.918297</td>\n",
       "      <td>0.907781</td>\n",
       "      <td>0.864195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542565</td>\n",
       "      <td>0.589581</td>\n",
       "      <td>0.681475</td>\n",
       "      <td>0.760325</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.874843</td>\n",
       "      <td>0.828300</td>\n",
       "      <td>0.821699</td>\n",
       "      <td>0.839504</td>\n",
       "      <td>0.847380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.901908</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.904083</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.945229</td>\n",
       "      <td>0.946572</td>\n",
       "      <td>0.945706</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.910453</td>\n",
       "      <td>0.867040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553107</td>\n",
       "      <td>0.603932</td>\n",
       "      <td>0.698232</td>\n",
       "      <td>0.774551</td>\n",
       "      <td>0.852588</td>\n",
       "      <td>0.887733</td>\n",
       "      <td>0.841563</td>\n",
       "      <td>0.834155</td>\n",
       "      <td>0.851384</td>\n",
       "      <td>0.857122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.905233</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.908222</td>\n",
       "      <td>0.932277</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.950163</td>\n",
       "      <td>0.948500</td>\n",
       "      <td>0.924609</td>\n",
       "      <td>0.912586</td>\n",
       "      <td>0.869533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>0.613221</td>\n",
       "      <td>0.708951</td>\n",
       "      <td>0.784403</td>\n",
       "      <td>0.861860</td>\n",
       "      <td>0.897210</td>\n",
       "      <td>0.850656</td>\n",
       "      <td>0.843442</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>0.865734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904827</td>\n",
       "      <td>0.902037</td>\n",
       "      <td>0.907663</td>\n",
       "      <td>0.932355</td>\n",
       "      <td>0.949386</td>\n",
       "      <td>0.950604</td>\n",
       "      <td>0.948925</td>\n",
       "      <td>0.924726</td>\n",
       "      <td>0.913070</td>\n",
       "      <td>0.870142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558286</td>\n",
       "      <td>0.612063</td>\n",
       "      <td>0.708292</td>\n",
       "      <td>0.784608</td>\n",
       "      <td>0.863076</td>\n",
       "      <td>0.899327</td>\n",
       "      <td>0.852818</td>\n",
       "      <td>0.846230</td>\n",
       "      <td>0.864053</td>\n",
       "      <td>0.869041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.910386</td>\n",
       "      <td>0.907658</td>\n",
       "      <td>0.912743</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.952833</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.951710</td>\n",
       "      <td>0.927236</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>0.872694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560027</td>\n",
       "      <td>0.617369</td>\n",
       "      <td>0.714657</td>\n",
       "      <td>0.789342</td>\n",
       "      <td>0.866453</td>\n",
       "      <td>0.904883</td>\n",
       "      <td>0.860934</td>\n",
       "      <td>0.854519</td>\n",
       "      <td>0.871977</td>\n",
       "      <td>0.875110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.351671</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.344629</td>\n",
       "      <td>0.347456</td>\n",
       "      <td>0.359713</td>\n",
       "      <td>0.354817</td>\n",
       "      <td>0.324301</td>\n",
       "      <td>0.301153</td>\n",
       "      <td>0.299411</td>\n",
       "      <td>0.295714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269912</td>\n",
       "      <td>0.283765</td>\n",
       "      <td>0.285817</td>\n",
       "      <td>0.289804</td>\n",
       "      <td>0.307366</td>\n",
       "      <td>0.326761</td>\n",
       "      <td>0.340221</td>\n",
       "      <td>0.345912</td>\n",
       "      <td>0.359393</td>\n",
       "      <td>0.352875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.337909</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.332659</td>\n",
       "      <td>0.335419</td>\n",
       "      <td>0.350456</td>\n",
       "      <td>0.341585</td>\n",
       "      <td>0.312984</td>\n",
       "      <td>0.289394</td>\n",
       "      <td>0.289576</td>\n",
       "      <td>0.284568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291808</td>\n",
       "      <td>0.299528</td>\n",
       "      <td>0.301428</td>\n",
       "      <td>0.306240</td>\n",
       "      <td>0.326543</td>\n",
       "      <td>0.338147</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.350097</td>\n",
       "      <td>0.362901</td>\n",
       "      <td>0.356399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.361319</td>\n",
       "      <td>0.352984</td>\n",
       "      <td>0.356819</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.375447</td>\n",
       "      <td>0.363563</td>\n",
       "      <td>0.335171</td>\n",
       "      <td>0.309871</td>\n",
       "      <td>0.312171</td>\n",
       "      <td>0.306592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290049</td>\n",
       "      <td>0.301184</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.315332</td>\n",
       "      <td>0.337371</td>\n",
       "      <td>0.349808</td>\n",
       "      <td>0.350836</td>\n",
       "      <td>0.361335</td>\n",
       "      <td>0.379264</td>\n",
       "      <td>0.373379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.401006</td>\n",
       "      <td>0.395408</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>0.402520</td>\n",
       "      <td>0.414076</td>\n",
       "      <td>0.401920</td>\n",
       "      <td>0.368543</td>\n",
       "      <td>0.338656</td>\n",
       "      <td>0.335536</td>\n",
       "      <td>0.323142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301809</td>\n",
       "      <td>0.316624</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>0.342717</td>\n",
       "      <td>0.364091</td>\n",
       "      <td>0.378778</td>\n",
       "      <td>0.370941</td>\n",
       "      <td>0.379012</td>\n",
       "      <td>0.401602</td>\n",
       "      <td>0.395907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.428266</td>\n",
       "      <td>0.423539</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.429570</td>\n",
       "      <td>0.439294</td>\n",
       "      <td>0.427313</td>\n",
       "      <td>0.391034</td>\n",
       "      <td>0.358806</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.337498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303183</td>\n",
       "      <td>0.321123</td>\n",
       "      <td>0.337467</td>\n",
       "      <td>0.353731</td>\n",
       "      <td>0.375026</td>\n",
       "      <td>0.392587</td>\n",
       "      <td>0.382113</td>\n",
       "      <td>0.389544</td>\n",
       "      <td>0.414888</td>\n",
       "      <td>0.408861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.894845  0.891381  0.895977  0.921408  0.939303  0.939943  0.941081   \n",
       "1    0.901908  0.899040  0.904083  0.928367  0.945229  0.946572  0.945706   \n",
       "2    0.905233  0.902608  0.908222  0.932277  0.948934  0.950163  0.948500   \n",
       "3    0.904827  0.902037  0.907663  0.932355  0.949386  0.950604  0.948925   \n",
       "4    0.910386  0.907658  0.912743  0.936699  0.952833  0.955100  0.951710   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "213  0.351671  0.343865  0.344629  0.347456  0.359713  0.354817  0.324301   \n",
       "214  0.337909  0.329563  0.332659  0.335419  0.350456  0.341585  0.312984   \n",
       "215  0.361319  0.352984  0.356819  0.360800  0.375447  0.363563  0.335171   \n",
       "216  0.401006  0.395408  0.399902  0.402520  0.414076  0.401920  0.368543   \n",
       "217  0.428266  0.423539  0.427507  0.429570  0.439294  0.427313  0.391034   \n",
       "\n",
       "          7         8         9    ...       168       169       170  \\\n",
       "0    0.918297  0.907781  0.864195  ...  0.542565  0.589581  0.681475   \n",
       "1    0.922280  0.910453  0.867040  ...  0.553107  0.603932  0.698232   \n",
       "2    0.924609  0.912586  0.869533  ...  0.560311  0.613221  0.708951   \n",
       "3    0.924726  0.913070  0.870142  ...  0.558286  0.612063  0.708292   \n",
       "4    0.927236  0.914956  0.872694  ...  0.560027  0.617369  0.714657   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "213  0.301153  0.299411  0.295714  ...  0.269912  0.283765  0.285817   \n",
       "214  0.289394  0.289576  0.284568  ...  0.291808  0.299528  0.301428   \n",
       "215  0.309871  0.312171  0.306592  ...  0.290049  0.301184  0.306667   \n",
       "216  0.338656  0.335536  0.323142  ...  0.301809  0.316624  0.329314   \n",
       "217  0.358806  0.353181  0.337498  ...  0.303183  0.321123  0.337467   \n",
       "\n",
       "          171       172       173       174       175       176       177  \n",
       "0    0.760325  0.840499  0.874843  0.828300  0.821699  0.839504  0.847380  \n",
       "1    0.774551  0.852588  0.887733  0.841563  0.834155  0.851384  0.857122  \n",
       "2    0.784403  0.861860  0.897210  0.850656  0.843442  0.860833  0.865734  \n",
       "3    0.784608  0.863076  0.899327  0.852818  0.846230  0.864053  0.869041  \n",
       "4    0.789342  0.866453  0.904883  0.860934  0.854519  0.871977  0.875110  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "213  0.289804  0.307366  0.326761  0.340221  0.345912  0.359393  0.352875  \n",
       "214  0.306240  0.326543  0.338147  0.343255  0.350097  0.362901  0.356399  \n",
       "215  0.315332  0.337371  0.349808  0.350836  0.361335  0.379264  0.373379  \n",
       "216  0.342717  0.364091  0.378778  0.370941  0.379012  0.401602  0.395907  \n",
       "217  0.353731  0.375026  0.392587  0.382113  0.389544  0.414888  0.408861  \n",
       "\n",
       "[218 rows x 178 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf = pd.DataFrame(data = projected) \n",
    "principalDf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
